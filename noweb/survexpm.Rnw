\section{Matrix exponentials and transition matrices}
For multi-state models, we need to compute the exponential of the transition
matrix, sometimes many times.
The matrix exponential is formally defined as
\begin{equation*}
  \exp(R) = I + \sum_{j=1}^\infty R^i/i!
  \end{equation*}
The computation is nicely solved by the expm package
\emph{if} we didn't need derivatives and/or high speed.  
We want both.

For the package there are three cases:
\begin{enumerate}
  \item If there is only one departure state, then there is a fast closed
    form solution, shown below.  This case occurs whenever an event time
    is unique, i.e., no other event times are tied with this one.  It also
    holds, by definition, for competing risk models.
  \item If the rate matrix $R$ is upper triangular and the (non-zero) diagonal
    elements are distinct, there is a fast matrix decomposition algorithm.
    If the transition matrix is acylic then it can be rearranged to be in upper
    triangular form.  The decomposition also gives a simple expression for
    the derivative.
  \item In the general case we use a Pade-Laplace algorithm: the same found 
    in the matexp package.
\end{enumerate}

For a rate matrix $R$, $R_{jk}$ is the rate of transition from state $j$ to
state $k$, and is itself an exponential $R_{jk} = \exp(\eta_{jk})$.
Thus all non-diagonal values must be $/ge 0$.  Transitions that do not occur
have rate 0. 
The diagonal element is determined by the constraint that row sums are 0.
Let $A= \exp(R)$.
Also be aware that $\exp(A)\exp(B) \ne \exp(A+B)$ for the case of matrices.

If there is only one non-zero diagonal element, $R_{jj}$ say, then
\begin{align*} 
    A_{jj} &= e^{R_{jj}} \\
    A_{jk} &= \left(1- e^{R_{jj}}\right) \frac{R_{jk}}/{\sum_{l\ne j} R_{jl}} \\
    A_{kk} &= 1; k\ne j 
\end{align*}
and all other elements of $A$ are zero.
The derivative of $A$ with respect to $\eta_{jk}$ will be 0 for all rows
except row $j$.
\begin{align*} 
  \frac{\partial A_{jj}}{\partial \eta_{jk}} &=
    \frac{\partial \exp(-\sum_{k!=j} \eta_{jk})}{\partial \eta_{jk}}  \\
   &= -\eta_{jk} A_{jj} \\
 \frac{\partial A_{jk}}{\partial \eta_{jk}} &= eta_{jk}A_{jj} 
     \;\mbox{single event type} \\
    \frac{\partial A_{jk}}{\partial \eta_{jm}}&=  
      A_{jj} eta_{jm}\frac{R_{jm}}{\sum_{l\ne j} R_{jl}} +
      (A_{jj} -1) \frac{\eta_{jm} (1- \sum_{l\ne j} R_{jl})}{(\sum_{l\ne j} R_{jl})^2}
\end{align*}
If time is continuous then most events will be at a unique event time, and this
fast computation will be the most common case.
    
If the state space is acylic, the case for many survival problems, then
we can reorder the states so that R is upper triangular.
In that case, the diagonal elements of R are the eigenvalues.  If these
are unique (ignoring the zeros), then an algorithm of Kalbfleisch and Lawless
gives both A and the derivatives of A in terms of a matrix decomposition.
For the remaining cases use the Pade' approximation as found in the
matexp package.
The overall stategy is the following:
\begin{enumerate} 
  \item Call \code{survexpmsetup} once, which will decide if the matrix is
    acyclic, and return a reorder vector if so or a flag if it is not.
    This determination is based on the possible transitions, e.g., on the
    transitions matrix from survcheck.
  \item Call \code{survexpm} for each individual transition matrix.
    In that routine
    \begin{itemize}
      \item First check for the simple case, otherwise
      \item Do not need derivatives: call survexpm
      \item Do need derivatives
        \begin{itemize}
          \item If upper triangular and no tied values, use the deriv routine
          \item Otherwise use the Pade routine
        \end{itemize}
    \end{itemize}
\end{enumerate}

<<survexpm>>=
survexpmsetup <- function(rmat) {
    # check the validity of the transition matrix, and determine if it
    #  is acyclic, i.e., can be reordered into an upper triangular matrix.
    if (!is.matrix(rmat) || nrow(rmat) != ncol(rmat) || any(diag(rmat) > 0) ||
        any(rmat[row(rmat) != col(rmat)] < 0))
        stop ("input is not a transition matrix")
    if (!is.logical(all.equal(rowSums(rmat), rep(0, ncol(rmat)))))
        stop("input is not a transition matrix")
    nc <- ncol(rmat)
    lower <- row(rmat) > col(rmat)
    if (all(rmat[lower] ==0))  return(0)  # already in order
    
    # score each state by (number of states it follows) - (number it precedes)
    temp <- 1*(rmat >0) # 0/1 matrix
    indx <- order(colSums(temp) - rowSums(temp))
    temp <- rmat[indx, indx]  # try that ordering
    if (all(temp[lower]== 0)) indx  # it worked!
    else -1  # there is a loop in the states
}
@ 

\subsection{Decompostion}
Based on Kalbfleisch and Lawless, ``The analysis of panel data under a 
Markov assumption'' (J Am Stat Assoc, 1985:863-871), the
rate matrix $R$ can be written as $ADA^{-1}$ for some matrix $A$, where
$D$ is a diagonal matrix of eigenvalues, provided all of the eigenvalues
are distinct.  Then $R^k = A D^k A^{-1}$, and using the definition of
a matrix exponential we see that
$\exp(R) = A \exp(D) A^{-1}$.  The exponential of a diagonal
matrix is simply a diagonal matrix of the exponentials.
The matrix $Rt$ for a scalar $t$ has decomposition $A\exp(Dt)A^{-1}$; a
single decompostion suffices for all values of $t$.

A particular example is
\begin{equation}
  R =
  \begin{pmatrix}
    r_{11} & r_{12} & r_{13} & 0 & 0 & r_{15}\\
    0 & r_{22} & 0 & r_{24} & 0 & r_{25}\\
    0 & 0 & r_{33} & r_{34} & r_{35} & r_{35}\\
    0 & 0 & 0 & r_{44} & r_{45} & r_{45} \\
    0 & 0 & 0 & 0 & r_{55} & r_{55} \\
    0 & 0 & 0 & 0 & 0 & 0
  \end{pmatrix}.
\end{equation}
Since this is a transition matrix the diagonal elements are constrained so that
row sums are zero: $r_{ii} = -\sum_{j\ne i} r_{ij}$.
Since R is an upper triangular matrix it's eigenvalues lie on the diagonal.
If none of the the eigenvalues are
repeated, then the Prentice result applies.

The decompostion is quite simple since $R$ is triangular.
We want the eigenvectors, i.e. solutions to 
\begin{align*}
  R v_i &= r_{ii} v_i \\
%  R v_2 &= r_{22} v_2 \\
%  R v_3 &= r_{33} v_3 \\
%  R v_4 &= r_{44} v_4 \\
%  R v_5 &= r_{55} v_5 \\
%  R v_6 &= r_{66} v_6
\end{align*}
for $i= 1, \dots, 6$, where $v_i$ are the colums of $V$. 

It turns out that the set of eigenvectors is
also upper triangular; we can solve for them one by one
using back substitution.
For the first eigenvector we have 
$v_1 = (1, 0,0,0,0,0)$.
For the second we have the equations
\begin{align*}
  r_{11} x + r_{12}y &=  r_{22} x \\
             r_{22}y &=  r_{22} y
\end{align*}
which has the solution $(r_{12}/(r_{22}- r_{11}), 1, 0,0,0,0)$,
and the process recurs for other rows.
Since $V$ is triangular the inverse of $V$ is upper triangular
and also easy to compute.

This approach fails if there are tied eigenvalues.
Kalbfleice and Lawless comment that this case is rare,
but one can then use a decomposition to Jordan canonical form re
Cox and Miller, the Theory of Stochastic Processes, 1965.
Although this leads to some nice theorems it does not give a 
simple comutational form, however, 
and it is easier to fall back on the pade routine.
At this time, the pade routine is as fast as the triangluar code,
at least for small matrices without deriviatives.

<<survexpm>>=
survexpm <- function(rmat, time=1.0, setup, eps=1e-6) {
    # rmat is a transition matrix, so the diagonal elements are 0 or negative
    if (length(rmat)==1) exp(rmat[1]*time)  #failsafe -- should never be called
    else {
        nonzero <- (diag(rmat) != 0)
        if (sum(nonzero ==0)) diag(nrow(rmat))  # expm(0 matrix) = identity
        if (sum(nonzero) ==1) {   # only one state had departures
            j <- which(nonzero)
            emat <- diag(nrow(rmat))
            temp <- exp(rmat[j,j] * time)
            emat[j,j] <- temp
            emat[j, -j] <- (1-temp)* rmat[j, -j]/sum(rmat[j,-j])
            emat
        }
        else if (missing(setup) || setup[1] < 0 ||
                 any(diff(sort(diag(rmat)))< eps)) pade(rmat*time)
        else {
            if (setup[1]==0) .Call(Ccdecomp, rmat, time)$P
            else {
                temp <- rmat
                temp[setup, setup] <- .Call(Ccdecomp, rmat[setup, setup], time)
                temp$P
            }
        }
    }
}
@ 

The routine below is modeled after the cholesky routines in the survival
library.  
To help with notation, the return values are labeled as in the 
Kalbfleisch and Lawless paper,
except that their Q = our rmat.  Q = A diag(d) Ainv and P= exp(Qt)

<<cdecomp>>=
/*
** Compute the eigenvectors for the upper triangular matrix R
*/
#include <math.h>
#include "R.h"
#include "Rinternals.h"

SEXP cdecomp(SEXP R2, SEXP time2) {
    int i,j,k;
    int nc, ii;
    
    static const char *outnames[]= {"d", "A", "Ainv", 
				    "P", ""};    
    SEXP rval, stemp;
    double *R, *A, *Ainv, *P;
    double *dd, temp, *ediag;
    double time;

    nc = ncols(R2);   /* number of columns */
    R = REAL(R2);
    time = asReal(time2);

    /* Make the output matrices as copies of R, so as to inherit
    **   the dimnames and etc
    */
    
    PROTECT(rval = mkNamed(VECSXP, outnames));
    stemp=  SET_VECTOR_ELT(rval, 0, allocVector(REALSXP, nc));
    dd = REAL(stemp);
    stemp = SET_VECTOR_ELT(rval, 1, allocMatrix(REALSXP, nc, nc));
    A = REAL(stemp);
    for (i =0; i< nc*nc; i++) A[i] =0;   /* R does not zero memory */
    stemp = SET_VECTOR_ELT(rval, 2, duplicate(stemp));
    Ainv = REAL(stemp);
    stemp = SET_VECTOR_ELT(rval, 3, duplicate(stemp));
    P = REAL(stemp);
   
    ediag = (double *) R_alloc(nc, sizeof(double));
    
    /* 
    **	Compute the eigenvectors
    **   For each column of R, find x such that Rx = kx
    **   The eigenvalue k is R[i,i], x is a column of A
    **  Remember that R is in column order, so the i,j element is in
    **   location i + j*nc
    */
    ii =0; /* contains i * nc */
    for (i=0; i<nc; i++) { /* computations for column i */
	dd[i] = R[i +ii];    /* the i,i diagonal element = eigenvalue*/
	A[i +ii] = 1.0;
        for (j=(i-1); j >=0; j--) {  /* fill in the rest */
            temp =0;
            for (k=j; k<=i; k++) temp += R[j + k*nc]* A[k +ii];
            A[j +ii] = temp/(dd[i]- R[j + j*nc]);
        }
	ii += nc;
    }
    
    /*
    ** Solve for A-inverse, which is also upper triangular. The diagonal
    **  of A and the diagonal of A-inverse are both 1.  At the same time 
    **  solve for P = A D Ainverse, where D is a diagonal matrix 
    **  with exp(eigenvalues) on the diagonal.
    ** P will also be upper triangular, and we can solve for it using
    **  nearly the same code as above.  The prior block had RA = x with A the
    **  unknown and x successive colums of the identity matrix. 
    **  We have PA = AD, so x is successively columns of AD.
    ** Imagine P and A are 4x4 and we are solving for the second row
    **  of P.  Remember that P[2,1]= A[2,3] = A[2,4] =0; the equations for
    **  this row of P are:
    **
    **    0*A[1,2] + P[2,2]A[2,2] + P[2,3] 0     + P[2,4] 0     = A[2,2] D[2]
    **    0*A[1,3] + P[2,2]A[2,3] + P[2,3]A[3,3] + P[2,4] 0     = A[2,3] D[3]
    **    0*A[1,4] + P[2,2]A[2,4] + P[2,3]A[3,4] + P[2,4]A[4,4] = A[2,4] D[4]
    **
    **  For A-inverse the equations are (use U= A-inverse for a moment)
    **    0*A[1,2] + U[2,2]A[2,2] + U[2,3] 0     + U[2,4] 0     = 1
    **    0*A[1,3] + U[2,2]A[2,3] + U[2,3]A[3,3] + U[2,4] 0     = 0
    **    0*A[1,4] + U[2,2]A[2,4] + U[2,3]A[3,4] + U[2,4]A[4,4] = 0
    */
    
    ii =0; /* contains i * nc */
    for (i=0; i<nc; i++) ediag[i] = exp(time* dd[i]);
    for (i=0; i<nc; i++) { 
	/* computations for column i of A-inverse */
	Ainv[i+ii] = 1.0 ;
	for (j=(i-1); j >=0; j--) {  /* fill in the rest of the column*/
	    temp =0;
	    for (k=j+1; k<=i; k++) temp += A[j + k*nc]* Ainv[k +ii];
	    Ainv[j +ii] = -temp;
	}
	
        /* column i of P */
	P[i + ii] = ediag[i];
        for (j=0; j<i; j++) {
	    temp =0;
            for (k=j; k<nc; k++) temp += A[j + k*nc] * Ainv[k+ii] * ediag[k];
            P[j+ii] = temp;
        }
        
	/* alternate computations for row i of P, does not use Ainv*/
	/*P[i +ii] = ediag[i];
	  for (j=i+1; j<nc; j++) { 
	      temp =0;
	      for (k=i; k<j; k++) temp += P[i+ k*nc]* A[k + j*nc];
              P[i + j*nc] = (A[i + j*nc]*ediag[j] - temp)/A[j + j*nc];
	  } 
        */
	ii += nc;
    }
    UNPROTECT(1);
    return(rval);
}
@ 

\subsection{Derivatives}
From Kalbfliesch and Lawless, the first derivative of 
$P = \exp(Rt)$ is
\begin{align*}
  \frac{\partial P}{\partial \theta} &= AVA^{-1} \\
     V_{ij} &= \left\{ \begin{array}{ll}
         G_{ij}(e^{d_i t} - e^{d_j t})/(d_i - d_j) & i \ne j \\
         G_{ii}t e^{d_it} & i=j 
         \end{array} \right. \\
       G&= A (\partial R /\partial \theta) A^{-1}
\end{align*}
The formula for the off diagonal elements collapses to give the formula for
the diagonal ones by an application of L'Hospital's rule (for the math
geeks).

Each off diagonal element of R is $\exp(X_i\beta)= \exp(\eta_i)$ for a fixed
vector $X_i$ --- we are computing the derivative at a particular trial value.
The first derivative with respect to
$\beta_j$ is then $X_{ij} \exp(\eta_{i})$.
Since the rows of R sum to a constant then the rows of 
its derivative must sum to zero;
we can fill in the diagonal element after the off diagonal ones are computed.
This notation has left something out: there is a separate $\eta$ vector
for each of the non-zero transitions, giving a matrix
of derivatives ($P$ is a matrix after all) for each $\beta_j$.

This computation is more bookkeeping than the earlier one, but no
single portion is particularly intensive computationally when the number
of states is modest.

The input will be the $X$ matrix row for the particular subject, 
the coefficient matrix, the rates matrix, time interval, and the mapping
vector from eta to the rates.  The last tells us where the zeros are.

<<survexpm>>=
derivative <- function(rmat, time, dR, setup, eps=1e-8) {
    if (missing(setup) || setup[1] <0 || any(diff(sort(diag(rmat)))< eps)) 
        return (pade(rmat*time, dR*time))

    if (setup==0) dlist <- .Call(Ccdecomp, rmat, time)
    else dlist <- .Call(Ccdecomp, rmat[setup, setup], time)
    ncoef <- dim(dR)[3]
    nstate <- nrow(rmat)
    
    dmat <- array(0.0, dim=c(nstate, nstate, ncoef))
    vtemp <- outer(dlist$d, dlist$d,
                   function(a, b) {
                       ifelse(abs(a-b)< eps, time* exp(time* (a+b)/2),
                         (exp(a*time) - exp(b*time))/(a-b))})

    # two transitions can share a coef, but only for the same X variable
    for (i in 1:ncoef) {
        G <- dlist$Ainv %*% dR[,,i] %*% dlist$A
        V <- G*vtemp
        dmat[,,i] <- dlist$A %*% V %*% dlist$Ainv
    }
    dlist$dmat <- dmat
    
    # undo the reordering, if needed
    if (setup[1] >0) {
        indx <- order(setup)
        dlist <- list(P = dlist$P[indx, indx],
                      dmat = apply(dmat,1:2, function(x) x[indx, indx]))
    }
                      
    dlist
}
@ 

The Pade approximation is found in the file pade.R.  There is a good discussion
of the problem at www.maths.manchester.ac.uk/~higham/talks/exp09.pdf.
The pade function copied code from the matexp package, which in turn is based
on Higham 2005.  Let B be a matrix and define
\begin{eqnarray*}
  r_m(B) &= p(B)/q(B) \\
  p(B)   &= \sum_{j=0^m} \frac{((2m-j)! m!}{(2m)!(m-j)! j!} B^j \\
    q(B) &= p(-B)
\end{eqnarray*}

The algorithm for calculating $\exp(A)$ is based on the following table
\begin{center}
\begin{tabular}{c|ccccc}
   $||A||_1$ & 0.15 & .25 & .95 & 2.1 & 3.4 \\
    m        & 3    & 5   &  7  & 9   & 13
\end{tabular} \end{center}
The 1 norm of a matrix is \code{max(colSums(A))}.  If the norm is $\le 3.4$
the $\exp(A) = r_m(A)$ using the table.
Otherwise, find $s$ such that $B = A/2^s$ has norm $<=3.4$ and use the table
method to find $\exp(B)$, then $\exp(A) \approx B^(2^s)$, the latter involves
repeated squaring of the matrix.  

The expm code has a lot of extra steps whose job is to make sure that elements
of $A$ are not too disparate in size.  Transition matrices are nice and we can
skip all of that.  This makes the pade function conserably faster than the
expm function from the Matrix library.  In fact, if there aren't any
tied event times, most elements of the rate matrix will be zero, and 
others are on the order of 1/(number at risk), so that $m=3$ is the most common
outcome. 
