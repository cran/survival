\section{Matrix exponentials and transition matrices}
For multi-state models, we need to compute the exponential of the transition
matrix, sometimes many times.
The matrix exponential is a hard problem, formally defined as
\begin{equation*}
  \exp(R) = I + \sum_{j=1}^\infty R^i/i!
  \end{equation*}
The computation is nicely solved by the expm package
\emph{if} we didn't need derivatives and/or high speed.  
We want both.
The key idea is from a paper by Kalbfleisch and Lawless: if the rate matrix
$R$ has distinct eigenvalues then $\exp(R)$ and its derivative can be written
in terms of a matrix decomposition.  
If $R$ is upper triangular this decompostion is itself very easy to compute.
If the transition matrix is acylic then it can be rearranged to be in upper
triangular form.  
As importantly, the decomposition leads to a simple computation for the
first derivative of each element.

Also be aware that $\exp(A)\exp(B) \ne \exp(A+B)$ for the case of matrices.

Nearly all the rate matrices encountered during an iteration will have
distint eigenvalues.
For the few which do not we can use the Pade' approximation found in the
matexp package.
If the rate matrix is upper triangular (\code{uppertri}), then the
eigenvalues are found on the diagonal of $R$.  
The overall stategy is the following:
\begin{enumerate} 
  \item Call \code{survexpmsetup} once, which will decide if the matrix is
    acyclic, and return a reorder vector if so or a flag if it is not.
  \item Call \code{survexpm} multiple times.  For that routine
    \begin{itemize}
      \item Do not need derivatives: call survexpm or pade as appropriate
      \item Do need derivatives
        \begin{itemize}
          \item If upper triangular and no tied values, use the deriv routine
          \item Otherwise use the Pade routine
        \end{itemize}
    \end{itemize}
\end{enumerate}

<<survexpm>>=
survexpmsetup <- function(rmat) {
    # check the validity of the transition matrix, and determine if it
    #  is acyclic, i.e., can be reordered into an upper triangular matrix.
    if (!is.matrix(rmat) || nrow(rmat) != ncol(rmat) || any(diag(rmat) > 0) ||
        any(rmat[row(rmat) != col(rmat)] < 0))
        stop ("input is not a transition matrix")
    if (!is.logical(all.equal(rowSums(rmat), rep(0, ncol(rmat)))))
        stop("input is not a transition matrix")
    nc <- ncol(rmat)
    lower <- row(rmat) > col(rmat)
    if (all(rmat[lower] ==0))  return(0)  # already in order
    
    # score each state by (number of states it follows) - (number it precedes)
    temp <- 1*(rmat >0) # 0/1 matrix
    indx <- order(colSums(temp) - rowSums(temp))
    temp <- rmat[indx, indx]  # try that ordering
    if (all(temp[lower]== 0)) indx  # it worked!
    else -1  # there is a loop in the states
}
@ 

\subsection{Decompostion}
Based on Kalbfleisch and Lawless, ``The analysis of panel data under a 
Markov assumption'' (J Am Stat Assoc, 1985:863-871), the
rate matrix $R$ can be written as $ADA^{-1}$ for some matrix $A$, where
$D$ is a diagonal matrix of eigenvalues, provided all of the eigenvalues
are distinct.
Then $\exp(R) = A \exp(D) A^{-1}$, and the exponential of a diagonal
matrix is simply a diagonal matrix of the exponentials.
The matrix $Rt$ for a scalar $t$ has decomposition $A\exp(Dt)A^{-1}$; a
single decompostion suffices for all values of $t$.

A particular example is
\begin{equation}
  R =
  \begin{pmatrix}
    r_{11} & r_{12} & r_{13} & 0 & 0 & r_{15}\\
    0 & r_{22} & 0 & r_{24} & 0 & r_{25}\\
    0 & 0 & r_{33} & r_{34} & r_{35} & r_{35}\\
    0 & 0 & 0 & r_{44} & r_{45} & r_{45} \\
    0 & 0 & 0 & 0 & r_{55} & r_{55} \\
    0 & 0 & 0 & 0 & 0 & 0
  \end{pmatrix}.
\end{equation}
Since this is a transition matrix the diagonal elements are constrained so that
row sums are zero: $r_{ii} = -\sum_{j\ne i} r_{ij}$.
Since R is an upper triangular matrix it's eigenvalues lie on the diagonal.
If none of the the eigenvalues are
repeated, then the Prentice result applies.

The decompostion is quite simple since $R$ is triangular.
We want the eigenvectors, i.e. solutions to 
\begin{align*}
  R v_i &= r_{ii} v_i \\
%  R v_2 &= r_{22} v_2 \\
%  R v_3 &= r_{33} v_3 \\
%  R v_4 &= r_{44} v_4 \\
%  R v_5 &= r_{55} v_5 \\
%  R v_6 &= r_{66} v_6
\end{align*}
for $i= 1, \dots, 6$, where $v_i$ are the colums of $V$. 

A sneaky fact is that the set of eigenvectors is
also upper triangular; we can solve for them one by one
using back substitution.
For the first eigenvector we have 
$v_1 = (1, 0,0,0,0,0)$.
For the second we have the equations
\begin{align*}
  r_{11} x + r_{12}y &=  r_{22} x \\
             r_{22}y &=  r_{22} y
\end{align*}
which has the solution $(r_{12}/(r_{22}- r_{11}), 1, 0,0,0,0)$,
and the process recurs for other rows.
Since $V$ is triangular the inverse of $V$ is upper triangular
and also easy to compute.

This approach fails if there are tied eigenvalues.
Kalbfleice and Lawless comment that this case is rare,
but one can then use a decomposition to Jordan canonical form re
Cox and Miller, the Theory of Stochastic Processes, 1965.
Although this leads to some nice theorems it does not give a 
simple comutational form, however, 
and it is easier to fall back on the pade routine.
At this time, the pade routine is as fast as the triangluar code,
at least for small matrices without deriviatives.

<<survexpm>>=
survexpm <- function(rmat, time=1.0, setup, eps=1e-6) {
    if (missing(setup) || setup[1] < 0 ||
        any(diff(sort(diag(rmat)))< eps)) pade(rmat*time)
    else {
        if (setup==1) .Call(Ccdecomp, rmat, time)$P
        else {
            temp <- rmat
            temp[setup, setup] <- .Call(Ccdecomp, rmat[setup, setup], time)
            temp$P
        }
    }
}
@ 

The routine below is modeled after the cholesky routines in the survival
library.  
To help with notation, the return values are labeled as in the 
Kalbfleisch and Lawless paper,
except that their Q = our rmat.  Q = A diag(d) Ainv and P= exp(Qt)

<<cdecomp>>=
/*
** Compute the eigenvectors for the upper triangular matrix R
*/
#include <math.h>
#include "R.h"
#include "Rinternals.h"

SEXP cdecomp(SEXP R2, SEXP time2) {
    int i,j,k;
    int nc, ii;
    
    static const char *outnames[]= {"d", "A", "Ainv", 
				    "P", ""};    
    SEXP rval, stemp;
    double *R, *A, *Ainv, *P;
    double *dd, temp, *ediag;
    double time;

    nc = ncols(R2);   /* number of columns */
    R = REAL(R2);
    time = asReal(time2);

    /* Make the output matrices as copies of R, so as to inherit
    **   the dimnames and etc
    */
    
    PROTECT(rval = mkNamed(VECSXP, outnames));
    stemp=  SET_VECTOR_ELT(rval, 0, allocVector(REALSXP, nc));
    dd = REAL(stemp);
    stemp = SET_VECTOR_ELT(rval, 1, allocMatrix(REALSXP, nc, nc));
    A = REAL(stemp);
    for (i =0; i< nc*nc; i++) A[i] =0;   /* R does not zero memory */
    stemp = SET_VECTOR_ELT(rval, 2, duplicate(stemp));
    Ainv = REAL(stemp);
    stemp = SET_VECTOR_ELT(rval, 3, duplicate(stemp));
    P = REAL(stemp);
   
    ediag = (double *) R_alloc(nc, sizeof(double));
    
    /* 
    **	Compute the eigenvectors
    **   For each column of R, find x such that Rx = kx
    **   The eigenvalue k is R[i,i], x is a column of A
    **  Remember that R is in column order, so the i,j element is in
    **   location i + j*nc
    */
    ii =0; /* contains i * nc */
    for (i=0; i<nc; i++) { /* computations for column i */
	dd[i] = R[i +ii];    /* the i,i diagonal element = eigenvalue*/
	A[i +ii] = 1.0;
	for (j=(i-1); j >=0; j--) {  /* fill in the rest */
	    temp =0;
	    for (k=j; k<=i; k++) temp += R[j + k*nc]* A[k +ii];
	    A[j +ii] = temp/(dd[i]- R[j + j*nc]);
	}
	ii += nc;
    }
    
    /*
    ** Solve for A-inverse, which is also upper triangular. The diagonal
    **  of A and the diagonal of A-inverse are both 1.  At the same time 
    **  solve for P = A D Ainverse, where D is a diagonal matrix 
    **  with exp(eigenvalues) on the diagonal.
    ** P will also be upper triangular, and we can solve for it using
    **  nearly the same code as above.  The prior block had RA = x with A the
    **  unknown and x successive colums of the identity matrix. 
    **  We have PA = AD, so x is successively columns of AD.
    ** Imagine P and A are 4x4 and we are solving for the second row
    **  of P.  Remember that P[2,1]= A[2,3] = A[2,4] =0; the equations for
    **  this row of P are:
    **
    **    0*A[1,2] + P[2,2]A[2,2] + P[2,3] 0     + P[2,4] 0     = A[2,2] D[2]
    **    0*A[1,3] + P[2,2]A[2,3] + P[2,3]A[3,3] + P[2,4] 0     = A[2,3] D[3]
    **    0*A[1,4] + P[2,2]A[2,4] + P[2,3]A[3,4] + P[2,4]A[4,4] = A[2,4] D[4]
    **
    **  For A-inverse the equations are (use U= A-inverse for a moment)
    **    0*A[1,2] + U[2,2]A[2,2] + U[2,3] 0     + U[2,4] 0     = 1
    **    0*A[1,3] + U[2,2]A[2,3] + U[2,3]A[3,3] + U[2,4] 0     = 0
    **    0*A[1,4] + U[2,2]A[2,4] + U[2,3]A[3,4] + U[2,4]A[4,4] = 0
    */
    
    ii =0; /* contains i * nc */
    for (i=0; i<nc; i++) ediag[i] = exp(time* dd[i]);
    for (i=0; i<nc; i++) { 
	/* computations for column i of A-inverse */
	Ainv[i+ii] = 1.0 ;
	for (j=(i-1); j >=0; j--) {  /* fill in the rest of the column*/
	    temp =0;
	    for (k=j+1; k<=i; k++) temp += A[j + k*nc]* Ainv[k +ii];
	    Ainv[j +ii] = -temp;
	}
	
        /* column i of P */
	P[i + ii] = ediag[i];
        for (j=0; j<i; j++) {
	    temp =0;
            for (k=j; k<nc; k++) temp += A[j + k*nc] * Ainv[k+ii] * ediag[k];
            P[j+ii] = temp;
        }
        
	/* alternate computations for row i of P, does not use Ainv*/
	/*P[i +ii] = ediag[i];
	  for (j=i+1; j<nc; j++) { 
	      temp =0;
	      for (k=i; k<j; k++) temp += P[i+ k*nc]* A[k + j*nc];
              P[i + j*nc] = (A[i + j*nc]*ediag[j] - temp)/A[j + j*nc];
	  } 
        */
	ii += nc;
    }
    UNPROTECT(1);
    return(rval);
}
@ 

\subsection{Derivatives}
From Kalbfliesch and Lawless, the first derivative of 
$P = \exp(Rt)$ is
\begin{align*}
  \frac{\partial P}{\partial \theta} &= AVA^{-1} \\
     V_{ij} &= \left\{ \begin{array}{ll}
         G_{ij}(e^{d_i t} - e^{d_j t})/(d_i - d_j) & i \ne j \\
         G_{ii}t e^{d_it} & i=j 
         \end{array} \right. \\
       G&= A (\partial R /\partial \theta) A^{-1}
\end{align*}
The formula for the off diagonal elements collapses to give the formula for
the diagonal ones by an application of L'Hospital's rule (for the math
geeks).

Each off diagonal element of R is $\exp(X_i\beta)= \exp(\eta_i)$ for a fixed
vector $X_i$ --- we are computing the derivative at a particular trial value.
The first derivative with respect to
$\beta_j$ is then $X_{ij} \exp(\eta_{i})$.
Since the rows of R sum to a constant then the rows of 
its derivative must sum to zero;
we can fill in the diagonal element after the off diagonal ones are computed.
This notation has left something out: there is a separate $\eta$ vector
for each of the non-zero transitions, there is a matrix
of derivatives ($P$ is a matrix after all) for each $\beta_j$.

This computation is more bookkeeping than the earlier one, but no
single portion is particularly intensive computationally when the number
of states is modest.

The input will be the $X$ matrix row for the particular subject, 
the coefficient matrix, the rates matrix, time interval, and the mapping
vector from eta to the rates.  The last tells us where the zeros are.

<<survexpm>>=
derivative <- function(rmat, time, dR, setup, eps=1e-8) {
    if (missing(setup) || setup[1] <0 || any(diff(sort(diag(rmat)))< eps)) 
        return (pade(rmat*time, dR*time))

    if (setup==0) dlist <- .Call(Ccdecomp, rmat, time)
    else dlist <- .Call(Ccdecomp, rmat[setup, setup], time)
    ncoef <- dim(dR)[3]
    nstate <- nrow(rmat)
    
    dmat <- array(0.0, dim=c(nstate, nstate, ncoef))
    vtemp <- outer(dlist$d, dlist$d,
                   function(a, b) {
                       ifelse(abs(a-b)< eps, time* exp(time* (a+b)/2),
                         (exp(a*time) - exp(b*time))/(a-b))})

    # two transitions can share a coef, but only for the same X variable
    for (i in 1:ncoef) {
        G <- dlist$Ainv %*% dR[,,i] %*% dlist$A
        V <- G*vtemp
        dmat[,,i] <- dlist$A %*% V %*% dlist$Ainv
    }
    dlist$dmat <- dmat
    
    # undo the reordering, if needed
    if (setup[1] >0) {
        indx <- order(setup)
        dlist <- list(P = dlist$P[indx, indx],
                      dmat = apply(dmat,1:2, function(x) x[indx, indx]))
    }
                      
    dlist
}
@ 

The Pade approximation is found in the file pade.R.  There is a good discussion
of the problem at www.maths.manchester.ac.uk/~higham/talks/exp09.pdf.
The pade function copied code from the matexp package, which in turn is based
on Higham 2005.  Let B be a matrix and define
\begin{eqnarray*}
  r_m(B) &= p(B)/q(B) \\
  p(B)   &= \sum_{j=0^m} \frac{((2m-j)! m!}{(2m)!(m-j)! j!} B^j \\
    q(B) &= p(-B)
\end{eqnarray*}

The algorithm for calculating $\exp(A)$ is based on the following table
\begin{center}
\begin{tabular}{c|ccccc}
   $||A||_1$ & 0.15 & .25 & .95 & 2.1 & 3.4 \\
    m        & 3    & 5   &  7  & 9   & 13
\end{tabular} \end{center}
The 1 norm of a matrix is \code{max(colSums(A))}.  If the norm is $\le 3.4$
the $\exp(A) = r_m(A)$ using the table.
Otherwise, find $s$ such that $B = A/2^s$ has norm $<=3.4$ and use the table
method to find $\exp(B)$, then $\exp(A) \approx B^(2^s)$, the latter involves
repeated squaring of the matrix.  

The expm code has a lot of extra steps whose job is to make sure that elements
of $A$ are not too disparate in size.  Transition matrices are nice and we can
skip all of that.  This makes the pade function conserably faster than the
expm function from the Matrix library.  In fact, if there aren't any
tied event times, most elements of the rate matrix will be zero, and 
others are on the order of 1/(number at risk), so that $m=3$ is the most common
outcome. 
